<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Home - Nathan Louis</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <meta name="viewport" content="width=device-width">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
	      <h1 class="avatar_header">Nathan Louis</h1>
	<div class="avatar">
		<img src="images/profile.jpg">
	</div>
	<p><center>Computer Vision PhD candidate at the University of Michigan</center></p>
	<h3>Contact info:</h3>
	<ul class="contact_urls">
	<!-- Icons from Icons8-->
		<li><a target="_blank" href="https://github.com/natlouis">
				<svg class="favicons" xmlns="http://www.w3.org/2000/svg" x="0px" y="0px"
				width="24" height="24"
				viewBox="0 0 24 24"
				style=" fill:#000000;">    <path d="M10.9,2.1c-4.6,0.5-8.3,4.2-8.8,8.7c-0.5,4.7,2.2,8.9,6.3,10.5C8.7,21.4,9,21.2,9,20.8v-1.6c0,0-0.4,0.1-0.9,0.1 c-1.4,0-2-1.2-2.1-1.9c-0.1-0.4-0.3-0.7-0.6-1C5.1,16.3,5,16.3,5,16.2C5,16,5.3,16,5.4,16c0.6,0,1.1,0.7,1.3,1c0.5,0.8,1.1,1,1.4,1 c0.4,0,0.7-0.1,0.9-0.2c0.1-0.7,0.4-1.4,1-1.8c-2.3-0.5-4-1.8-4-4c0-1.1,0.5-2.2,1.2-3C7.1,8.8,7,8.3,7,7.6C7,7.2,7,6.6,7.3,6 c0,0,1.4,0,2.8,1.3C10.6,7.1,11.3,7,12,7s1.4,0.1,2,0.3C15.3,6,16.8,6,16.8,6C17,6.6,17,7.2,17,7.6c0,0.8-0.1,1.2-0.2,1.4 c0.7,0.8,1.2,1.8,1.2,3c0,2.2-1.7,3.5-4,4c0.6,0.5,1,1.4,1,2.3v2.6c0,0.3,0.3,0.6,0.7,0.5c3.7-1.5,6.3-5.1,6.3-9.3 C22,6.1,16.9,1.4,10.9,2.1z"></path></svg> GitHub</a></li>
		<li><a target="_blank" href="https://www.linkedin.com/in/nathan-louis-05266887/">
				<svg class="favicons" xmlns="http://www.w3.org/2000/svg" x="0px" y="0px"
				width="24" height="24"
				viewBox="0 0 24 24"
				style=" fill:#000000;">    <path d="M 5 3 C 3.895 3 3 3.895 3 5 L 3 19 C 3 20.105 3.895 21 5 21 L 19 21 C 20.105 21 21 20.105 21 19 L 21 5 C 21 3.895 20.105 3 19 3 L 5 3 z M 5 5 L 19 5 L 19 19 L 5 19 L 5 5 z M 7.7792969 6.3164062 C 6.9222969 6.3164062 6.4082031 6.8315781 6.4082031 7.5175781 C 6.4082031 8.2035781 6.9223594 8.7167969 7.6933594 8.7167969 C 8.5503594 8.7167969 9.0644531 8.2035781 9.0644531 7.5175781 C 9.0644531 6.8315781 8.5502969 6.3164062 7.7792969 6.3164062 z M 6.4765625 10 L 6.4765625 17 L 9 17 L 9 10 L 6.4765625 10 z M 11.082031 10 L 11.082031 17 L 13.605469 17 L 13.605469 13.173828 C 13.605469 12.034828 14.418109 11.871094 14.662109 11.871094 C 14.906109 11.871094 15.558594 12.115828 15.558594 13.173828 L 15.558594 17 L 18 17 L 18 13.173828 C 18 10.976828 17.023734 10 15.802734 10 C 14.581734 10 13.930469 10.406562 13.605469 10.976562 L 13.605469 10 L 11.082031 10 z"></path></svg> LinkedIn</a></li>
		<li><a href="mailto:natlouis@umich.edu"><img class="favicons" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABgAAAAYCAYAAADgdz34AAAABmJLR0QA/wD/AP+gvaeTAAAAtElEQVRIie3TQQpBURjF8R9migUo2YJSliEjS7AFW7AFWzAxsAqlrIGBOWVGz8CVF89zEym9U6de3z3v/Ou7XQr9WqXUd/KN7vKHSx+UBehh/UbXFoO8QOK2pirGOKbmz3zCBLWMnkzAHK0wa2ORU75CN2QbmMYAEhwwQsVljUPsXpzv7zpyAVcv0QnnTcyCm2HWCZmsf6MA6R3XU9mYO4oGXL1BP3gTkce/PrQC8GeAQr/XGQz+Xbwnnbx7AAAAAElFTkSuQmCC"> natlouis@umich.edu</a></li>

		<li><a href="docs/natlouis_cv.pdf"><img class="favicons" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABgAAAAYCAYAAADgdz34AAAABmJLR0QA/wD/AP+gvaeTAAAATElEQVRIiWNgGOqAEYvYf2qayUShYQQBzS1gISCPLQixAZzBOuA+oDTCB94HsDj4j8ZHBwMXB0M/o43GAUEzR+OAIBj6cUBzC4Y+AAATxAwulfy0/AAAAABJRU5ErkJggg=="> Curriculum Vitae</a></li>
		<li><a href="https://scholar.google.com/citations?user=F1fgFYMAAAAJ&hl=en&authuser=1">Google Scholar profile</a></li>
	</ul>

      </header>
      <section>
				<h2>About Me</h2>
				<p>Currently, I am a EECS Ph.D candidate at the University of Michigan, Ann Arbor. I'm advised by <a target="_blank" href="https://web.eecs.umich.edu/~jjcorso/">Dr. Jason Corso</a> and 
				my primary research area is Computer Vision, particularly video understanding.</p>

				<p>While video understanding encompasses various tasks and problems within the video domain, my research interests are generic object tracking, video object detection, human pose estimation, human pose tracking.
				My previous efforts so far comprise of video object grounding and single target object tracking by learning motion models from Kalman filters.</p>

				<p>I completed my B.S in Electrical Engineering at Kennesaw State University in July 2017. I completed my Master's requirements at the University of Michigan in May 2019.</p>

				<h2>Publications</h2>
				<ul>
					<li><strong>N Louis</strong>, L Zhou, SJ Yule, RD Dias, M Manojlovich, FD Pagani, and JJ Corso. "Temporally Guided Articulated Hand Pose Tracking in Surgical Videos". <i>arXiv preprint 2021</i>. <a target="_blank" href="https://arxiv.org/pdf/2101.04281.pdf">Paper</a></li>
					<li>MR Ganesh, E Hofesmann, <strong>N Louis</strong>, and JJ Corso. "ViP: Video Platform for PyTorch", <i>arXiv preprint 2019</i>. <a target="_blank" href="https://arxiv.org/pdf/1910.02793.pdf">Paper</a>. <a target="_blank" href="https://github.com/MichiganCOG/ViP">Code</a></li>
					<li>L Zhou, <strong>N Louis</strong>, and JJ Corso. "Weakly-Supervised Video Object Grounding from Text by Loss Weighting and Object Interaction", <i>BMVC 2018</i>. <a target="_blank" href="https://arxiv.org/pdf/1805.02834.pdf">Paper</a>. <a target="_blank" href="https://github.com/MichiganCOG/Video-Grounding-from-Text">Code</a></li>
				</ul>

				<h2>Projects</h2>
				<h3>ViP: Video Platform for PyTorch</h3>
				<p> For this work, we developed a deep learning-based framework we call the Video Platform for PyTorch (ViP). We design it as a way to prototype and benchmark computer vision models in the video domain.
				ViP is built with flexibility and modularity in mind allowing for a single unified interface applicable to all video problem domains, easily reproducible experimental setups, and rapid prototyping of video models. 
				<a target="_blank" href="https://arxiv.org/pdf/1910.02793.pdf">[PDF]</a> <a target="_blank" href="https://github.com/MichiganCOG/ViP">[Code]</a></p>
				<img src="images/workshop_figure.png">

				<h3>Learning Motion Models for Robust Visual Object Tracking</h3>
				<p> This is from my qualification exams project regarding visual object tracking in computer vision. Here I investigated using state estimation theory in combination with a deep learning framework to produce robust tracking coordinate positions. I used a Siamese CNN to encode my observations followed by recent works with LSTM-KF, using recurrent neural networks to produce a motion model and covariance estimates for Kalman Filter updates. Results are reported on the ImageNet Video Object Detection dataset and compared to additional baselines. <a href="docs/quals_report.pdf">[PDF]</a></p>
				<img src="images/quals_figure.png">
				<h3>Weakly-Supervised Video Object Grounding from Text by Loss Weighting and Object Interaction</h3>
				<p> Here we studied weakly-supervised video object grounding: given a video segment and a corresponding descriptive sentence, the goal is to localize objects that are mentioned from the sentence in the video. During training, no object bounding boxes are available, but the set of possible objects to be grounded is known beforehand. 
				Existing approaches in the image domain that use Multiple Instance Learning (MIL) to ground objects by enforcing matches between visual and semantic features. We introduce a weak supervisory signal from the segment level to frames that likely contain the target object and an alternative penalty loss for frames that are unlikely to contain the target objects. We also leverage the interactions among objects as a textual guide for the grounding. Our model is evaluated on the newly- collected benchmark <a target="_blank" href="http://youcook2.eecs.umich.edu">YouCook2-BoundingBox</a> and show improvements over competitive baselines. <a target="_blank" href="https://arxiv.org/pdf/1805.02834.pdf">[PDF]</a> <a target="_blank" href="https://github.com/MichiganCOG/Video-Grounding-from-Text">[Code]</a></p>
				<img src="images/bmvc_figure.png">

      </section>
      <footer>
      </footer>
    </div>
    <script src="javascripts/scale.fix.js"></script>
  </body>
</html>
